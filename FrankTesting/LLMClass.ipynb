{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached https://files.pythonhosted.org/packages/64/62/f19d1e9023aacb47241de3ab5a5d5fedf32c78a71a9e365bb2153378c141/python_dotenv-0.21.1-py3-none-any.whl\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.21.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 24.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#%pip install --user pandas\n",
    "#%pip install --user graphviz\n",
    "#%pip install --user torch\n",
    "#%pip install --user transformers\n",
    "#%pip install --user nltk\n",
    "#%pip install --user openai\n",
    "#%pip install --user python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "# Get the OpenAI API key from the environment variables\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv('GPT_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT Response: ChatCompletionMessage(content='Artificial Intelligence (AI) is a field of computer science that involves creating machines or systems that can perform tasks that typically require human intelligence. These tasks include things like learning, problem-solving, understanding natural language, and making decisions. AI systems learn from data, identify patterns, and make decisions or predictions based on that information. Examples of AI in everyday life include virtual assistants like Siri or Alexa, recommendation systems on streaming platforms, and autonomous vehicles.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "class LLMEndpointBase(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def ask(self, prompt_dict: Dict[str, str]) -> str:\n",
    "        \"\"\"\n",
    "        Ask the LLM endpoint something\n",
    "\n",
    "        Arguments:\n",
    "            prompt_dict: A dictionary with the following keys:\n",
    "                systemRole: The system prompt for this user\n",
    "                user: The current user\n",
    "                context: The previous context\n",
    "                message: The message to the LLM agent\n",
    "                model: The designated model to be used.\n",
    "        \n",
    "        Returns:\n",
    "            response: response from LLM agent\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class ChatGPTEndpoint(LLMEndpointBase):\n",
    "\n",
    "    def ask(self, prompt_dict: Dict[str, str]) -> str:\n",
    "        try:\n",
    "            # Create a prompt from the prompt_dict\n",
    "            inputmessages = [\n",
    "                {\"role\": \"system\", \"content\": prompt_dict['systemRole']},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt_dict['user']} {prompt_dict['context']} {prompt_dict['message']}\"}\n",
    "            ]\n",
    "\n",
    "            # Make a request to the OpenAI API\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",  # Specify the model you want to use\n",
    "                messages=inputmessages,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            return response.choices[0].message\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the prompt_dict according to the required structure\n",
    "    prompt_dict = {\n",
    "        \"systemRole\": \"Explain concepts in simple terms\",\n",
    "        \"user\": \"Test User\",\n",
    "        \"context\": \"Previous conversation context if any\",\n",
    "        \"message\": \"Explain the concept of artificial intelligence.\"\n",
    "        \"\"\n",
    "    }\n",
    "    \n",
    "    # Create an instance of ChatGPTEndpoint\n",
    "    endpoint = ChatGPTEndpoint()\n",
    "    \n",
    "    # Get the response from the ChatGPT endpoint\n",
    "    response = endpoint.ask(prompt_dict)\n",
    "    \n",
    "    if response:\n",
    "        print(\"ChatGPT Response:\", response)\n",
    "    else:\n",
    "        print(\"Failed to get response from ChatGPT.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
